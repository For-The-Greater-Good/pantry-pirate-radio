# Scraper Implementation Notes: {{food_bank_name}}

**Issue:** #{{issue_number}}
**Scraper:** `{{scraper_name}}`
**Created:** {{date}}
**Status:** {{status}}

---

## Website Analysis

- **URL:** {{url}}
- **Page Type:** {{page_type}}
  - Static HTML / React SPA / WordPress / Other
- **Data Structure:** {{data_structure}}
  - HTML tables / Div lists / Map markers / API endpoint / PDF
- **JavaScript Required:** {{js_required}}
  - Yes / No / Partial

### Key Observations

{{website_observations}}

---

## Implementation Decisions

### Scraping Approach

**Method Selected:** {{scraping_method}}
- [ ] HTML Parsing (BeautifulSoup)
- [ ] API Endpoint (httpx + JSON)
- [ ] Browser Automation (Playwright)
- [ ] Hybrid (combination)
- [ ] Other: ___________

**Rationale:** {{approach_rationale}}

### Key Selectors / Endpoints

{{selectors_or_endpoints}}

Example:
```
CSS Selectors:
  - table.locations tr
  - .location-name
  - .location-address

API Endpoints:
  - GET https://example.org/api/locations
  - Returns: JSON array of location objects
```

### Fields Captured

- [ ] Name (required)
- [ ] Address (required)
- [ ] Phone
- [ ] Hours
- [ ] Services
- [ ] Eligibility Requirements
- [ ] Notes
- [ ] Other: ___________

**Notes on Field Extraction:**

{{field_extraction_notes}}

---

## Similar Scrapers Referenced

{{similar_scrapers}}

Example:
```
1. food_bank_of_alaska_ak_scraper.py
   - Similar because: HTML table structure
   - Borrowed pattern: Table row iteration

2. food_bank_of_iowa_ia_scraper.py
   - Similar because: Div-based layout
   - Borrowed pattern: CSS selector strategy
```

---

## Testing Results

### Syntax Validation

- **Status:** {{syntax_status}}
- **Command:** `./bouy test --pytest tests/test_scraper/test_{{scraper_name}}_scraper.py --collect-only`
- **Result:** {{syntax_result}}

### Dry Run

- **Status:** {{dry_run_status}}
- **Command:** `./bouy scraper-test {{scraper_name}}`
- **Locations Found:** {{location_count}}
- **Errors:** {{dry_run_errors}}

### Sample Location

```
{{sample_location_data}}
```

### Unit Tests

- **Status:** {{unit_test_status}}
- **Command:** `./bouy test --pytest tests/test_scraper/test_{{scraper_name}}_scraper.py -v`
- **Tests Passed:** {{tests_passed}} / {{tests_total}}
- **Coverage:** {{coverage_percent}}%

---

## Implementation Checklist

### Initial Setup
- [ ] Issue selected and validated
- [ ] Vivery check completed (not detected)
- [ ] Website analyzed
- [ ] Similar scrapers reviewed
- [ ] Approach decided

### Code Generation
- [ ] Scraper file created: `app/scraper/scrapers/{{scraper_name}}_scraper.py`
- [ ] Test file created: `tests/test_scraper/test_{{scraper_name}}_scraper.py`
- [ ] GitHub issue labeled `in-progress`
- [ ] Template customized with actual logic

### Implementation
- [ ] Scraping logic implemented
- [ ] Error handling added
- [ ] Field validation included
- [ ] No geocoding logic (validator handles this)
- [ ] Comments and documentation added

### Testing
- [ ] Syntax validation passed
- [ ] Dry run successful
- [ ] Unit tests passing
- [ ] Full test suite passing: `./bouy test`

### Finalization
- [ ] Code reviewed
- [ ] Documentation complete
- [ ] PR created
- [ ] Issue updated with PR number
- [ ] PR merged
- [ ] Issue marked as completed

---

## Challenges & Solutions

### Challenge 1: {{challenge_1_title}}

**Problem:** {{challenge_1_description}}

**Solution:** {{challenge_1_solution}}

### Challenge 2: {{challenge_2_title}}

**Problem:** {{challenge_2_description}}

**Solution:** {{challenge_2_solution}}

---

## Development Commands Reference

### Testing
```bash
# Run specific test file
./bouy test --pytest tests/test_scraper/test_{{scraper_name}}_scraper.py

# Run with verbose output
./bouy test --pytest tests/test_scraper/test_{{scraper_name}}_scraper.py -v

# Run dry run (no database commit)
./bouy scraper-test {{scraper_name}}

# Full execution
./bouy exec app python3 -m app.scraper {{scraper_name}}

# Run all tests before committing
./bouy test
```

### Progress Tracking
```bash
# Update issue status
./bouy exec app python3 scripts/feeding-america/update_scraper_progress.py

# Mark as completed
./bouy exec app python3 scripts/feeding-america/update_scraper_progress.py --completed {{issue_number}}

# Add note to issue
./bouy exec app python3 scripts/feeding-america/update_scraper_progress.py --note "Implementation complete"
```

### Pull Request
```bash
# Create PR
gh pr create \
  --title "Add {{food_bank_name}} ({{state}}) scraper" \
  --body "Implements scraper for issue #{{issue_number}}"

# Link PR to issue
gh issue comment {{issue_number}} --body "PR: #[PR_NUMBER]"
```

---

## Additional Notes

{{additional_notes}}

---

## Metadata

- **Generated by:** `/scrape` command
- **Template Version:** 1.0
- **Last Updated:** {{last_updated}}

# Datasette Viewer

## Overview

[Datasette](https://datasette.io/) is an open-source tool for exploring and publishing data. In Pantry Pirate Radio, it serves as a **read-only web interface** for exploring the SQLite database that is automatically exported from PostgreSQL by the HAARRRvest Publisher service.

## Data Flow Architecture

```plaintext
┌──────────────┐
│  PostgreSQL  │
│   Database   │
└──────┬───────┘
       │
       ▼
┌──────────────────┐
│   HAARRRvest     │
│   Publisher      │
│ (Every 5 min)    │
└──────┬───────────┘
       │
       ▼
┌──────────────────┐
│  SQLite Export   │
│ /data-repo/      │
│ sqlite/*.sqlite  │
└──────┬───────────┘
       │
       ▼
┌──────────────────┐
│    Datasette     │
│  Web Interface   │
│  Port 8001       │
└──────────────────┘
```

## Accessing Datasette

### Using Bouy Commands

```bash
# Start all services including Datasette
./bouy up

# In production mode
./bouy up --prod

# Access Datasette at:
# http://localhost:8001

# Check if Datasette is running
./bouy ps | grep datasette

# View Datasette logs
./bouy logs datasette

# Restart Datasette
./bouy down datasette && ./bouy up datasette
```

### Direct URLs

- **Local Development**: http://localhost:8001
- **Production**: http://your-server:8001
- **API Endpoint**: http://localhost:8001/pantry_pirate_radio.json
- **GraphQL**: http://localhost:8001/graphql

## Features and Capabilities

### Data Exploration

1. **Interactive SQL Queries**
   - Write and execute custom SQL queries
   - Save queries for reuse
   - Share query URLs with others

2. **Table Browsing**
   - View all tables and their data
   - Filter and sort records
   - Faceted search on categorical data

3. **Data Export**
   - Download data as CSV, JSON, or TSV
   - Export individual tables or query results
   - API access for programmatic data retrieval

### Geographic Visualization

Datasette automatically provides map visualizations for location data:

- **Cluster Maps**: Groups nearby locations for better performance
- **Individual Markers**: Shows exact location points
- **Popups**: Display location details on click

The exporter converts PostGIS geometry to latitude/longitude columns for compatibility.

### Installed Plugins

The Datasette instance includes these pre-installed plugins:

| Plugin | Purpose |
|--------|---------|
| `datasette-cluster-map` | Interactive clustered maps for geographic data |
| `datasette-leaflet` | Leaflet map visualizations |
| `datasette-graphql` | GraphQL API endpoint |
| `datasette-dashboards` | Custom dashboards and charts |
| `datasette-block-robots` | Prevents search engine indexing |

## Configuration

### Datasette Settings

Configured in Docker Compose with these settings:

```yaml
--setting sql_time_limit_ms 10000    # 10 second query timeout
--setting max_returned_rows 5000     # Maximum rows per query
--setting allow_download 1           # Enable CSV/JSON downloads
--setting default_page_size 50       # Rows per page
--setting base_url /                 # Base URL path
```

### Metadata Configuration

The `metadata.json` file is automatically generated by HAARRRvest Publisher:

```json
{
  "title": "Pantry Pirate Radio Data",
  "description": "Food assistance program data",
  "databases": {
    "pantry_pirate_radio": {
      "tables": {
        "organization": {
          "description": "Organizations providing services"
        },
        "location": {
          "description": "Physical locations of services"
        },
        "service": {
          "description": "Services offered by organizations"
        }
      }
    }
  }
}
```

## SQLite Export Process

### Automatic Export

HAARRRvest Publisher exports data every 5 minutes:

1. **Data Export**: PostgreSQL → SQLite using `app.datasette.exporter`
2. **View Creation**: Adds convenience views for common queries
3. **Metadata Generation**: Creates metadata.json for Datasette
4. **Git Commit**: Pushes to HAARRRvest repository

### Manual Export

```bash
# Trigger manual SQLite export
./bouy exec haarrrvest-publisher python -m app.datasette.exporter \
  --output /data-repo/sqlite/pantry_pirate_radio.sqlite

# Or trigger full HAARRRvest pipeline
./bouy haarrrvest
```

### Export Contents

The SQLite database includes:

- All tables from PostgreSQL (except PostGIS system tables)
- Converted geometry fields (latitude/longitude)
- Custom views for easier querying
- Full-text search indexes
- Proper data types and constraints

## Using Datasette

### Basic Queries

```sql
-- Find all food pantries in Brooklyn
SELECT * FROM location 
WHERE city = 'Brooklyn' 
  AND service_type LIKE '%food%'

-- Organizations with most locations
SELECT o.name, COUNT(l.id) as location_count
FROM organization o
JOIN location l ON o.id = l.organization_id
GROUP BY o.id, o.name
ORDER BY location_count DESC
LIMIT 10

-- Services by day of week
SELECT day_of_week, COUNT(*) as service_count
FROM service_schedule
GROUP BY day_of_week
ORDER BY service_count DESC
```

### API Access

```bash
# Get all organizations as JSON
curl http://localhost:8001/pantry_pirate_radio/organization.json

# Query with filters
curl "http://localhost:8001/pantry_pirate_radio/location.json?city=Brooklyn&_size=10"

# Execute SQL query via API
curl -X POST http://localhost:8001/pantry_pirate_radio.json \
  -d "sql=SELECT * FROM organization LIMIT 5"

# GraphQL query
curl http://localhost:8001/graphql \
  -H "Content-Type: application/json" \
  -d '{"query": "{ organization { nodes { name } } }"}'
```

### Custom Views

The exporter creates these convenience views:

- `location_master` - Comprehensive location data with related information
- Additional views based on common query patterns

## Troubleshooting

### Common Issues

1. **"Waiting for SQLite database..."**
   ```bash
   # Check HAARRRvest publisher status
   ./bouy ps | grep haarrrvest
   
   # Verify SQLite file exists
   ./bouy exec haarrrvest-publisher ls -la /data-repo/sqlite/
   
   # Trigger manual export
   ./bouy haarrrvest
   ```

2. **Database Not Updating**
   ```bash
   # Check publisher logs
   ./bouy logs haarrrvest-publisher --tail 50
   
   # Restart publisher to force update
   ./bouy down haarrrvest-publisher && ./bouy up haarrrvest-publisher
   ```

3. **Maps Not Showing**
   ```bash
   # Verify location data has coordinates
   ./bouy exec app python -c "
   from app.database import get_session
   from app.models import Location
   with get_session() as session:
       locs = session.query(Location).filter(
           Location.latitude != None,
           Location.longitude != None
       ).count()
       print(f'Locations with coordinates: {locs}')
   "
   ```

4. **Permission Errors**
   ```bash
   # Check volume permissions
   ./bouy exec datasette ls -la /data-repo/sqlite/
   
   # Fix permissions if needed
   ./bouy exec haarrrvest-publisher chmod 644 /data-repo/sqlite/*.sqlite
   ```

## Development and Customization

### Adding Plugins

Edit `.docker/images/datasette/Dockerfile`:

```dockerfile
RUN pip install \
    datasette-cluster-map \
    datasette-leaflet \
    datasette-graphql \
    datasette-dashboards \
    datasette-block-robots \
    datasette-your-new-plugin  # Add new plugin here
```

Then rebuild:
```bash
./bouy build datasette
```

### Creating Custom Views

Edit `app/datasette/exporter.py` to add views:

```python
def create_datasette_views(conn: sqlite3.Connection) -> None:
    """Create custom views for Datasette."""
    
    # Example: Services by organization
    conn.execute("""
        CREATE VIEW IF NOT EXISTS services_by_org AS
        SELECT 
            o.name as organization,
            COUNT(s.id) as service_count,
            GROUP_CONCAT(s.name) as services
        FROM organization o
        LEFT JOIN service s ON o.id = s.organization_id
        GROUP BY o.id
    """)
```

### Custom Metadata

Modify metadata generation in `app/haarrrvest_publisher/service.py`:

```python
metadata = {
    "title": "Your Custom Title",
    "description": "Your description",
    "databases": {
        "pantry_pirate_radio": {
            "tables": {
                # Table-specific metadata
            }
        }
    }
}
```

## Performance Optimization

### Query Performance

```bash
# Check slow queries
./bouy exec datasette sqlite3 /data-repo/sqlite/pantry_pirate_radio.sqlite \
  "EXPLAIN QUERY PLAN SELECT * FROM your_slow_query"

# Add indexes if needed (in exporter)
conn.execute("CREATE INDEX idx_location_city ON location(city)")
```

### Cache Configuration

Datasette caches query results by default. Clear cache by restarting:

```bash
./bouy down datasette && ./bouy up datasette
```

## Security Considerations

1. **Read-Only Access**: Datasette provides read-only access to data
2. **No Authentication**: Default setup has no authentication (add datasette-auth-passwords if needed)
3. **Robot Blocking**: Search engines are blocked via datasette-block-robots
4. **Query Limits**: Timeout and row limits prevent resource exhaustion

## Integration with Other Services

### HAARRRvest Publisher
- Generates SQLite database every 5 minutes
- Manages Git synchronization
- Creates metadata.json

### PostgreSQL Database
- Source of truth for all data
- Changes reflected in next export cycle

### API Service
- Write operations go through API
- Datasette is read-only viewer

## Best Practices

1. **Regular Monitoring**: Check export logs for failures
2. **Query Optimization**: Use views for complex queries
3. **Data Freshness**: Remember 5-minute lag from PostgreSQL
4. **Backup Strategy**: SQLite files are versioned in Git
5. **Documentation**: Document custom views and queries

## Related Documentation

- [HAARRRvest Publisher](./haarrrvest-publisher.md) - SQLite export and Git sync
- [Database Backup](./database-backup.md) - Backup strategies
- [Architecture](./architecture.md) - System design overview
- [API Documentation](http://localhost:8000/docs) - Write operations
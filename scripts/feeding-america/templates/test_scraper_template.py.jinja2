"""Tests for {{ food_bank_name }} scraper."""

import asyncio
import json
from typing import Any, Dict, List
from unittest.mock import AsyncMock, Mock, patch

import httpx
import pytest
import requests

from app.scraper.{{ module_name }}_scraper import {{ class_name }}Scraper


@pytest.fixture
def mock_html_response() -> str:
    """Sample HTML response for testing."""
    # TODO: Add actual HTML sample from the food bank website
    return """
    <html>
    <body>
        <div class="location">
            <h3>Sample Food Pantry</h3>
            <p class="address">123 Main St, City, {{ state }} 12345</p>
            <p class="phone">(555) 123-4567</p>
            <p class="hours">Mon-Fri 9am-5pm</p>
        </div>
    </body>
    </html>
    """


@pytest.fixture
def mock_json_response() -> Dict[str, Any]:
    """Sample JSON response for testing."""
    # TODO: Add actual JSON sample if the food bank uses an API
    return {
        "locations": [
            {
                "name": "Sample Food Pantry",
                "address": "123 Main St, City, {{ state }} 12345",
                "phone": "(555) 123-4567",
                "hours": "Mon-Fri 9am-5pm"
            }
        ]
    }


@pytest.fixture
def scraper() -> {{ class_name }}Scraper:
    """Create scraper instance for testing."""
    return {{ class_name }}Scraper(test_mode=True)


@pytest.mark.asyncio
async def test_download_html_success(scraper: {{ class_name }}Scraper, mock_html_response: str):
    """Test successful HTML download."""
    with patch('requests.get') as mock_get:
        mock_response = Mock()
        mock_response.text = mock_html_response
        mock_response.raise_for_status = Mock()
        mock_get.return_value = mock_response
        
        result = await scraper.download_html()
        
        assert result == mock_html_response
        mock_get.assert_called_once_with(
            scraper.url,
            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'},
            timeout=scraper.timeout
        )


@pytest.mark.asyncio
async def test_download_html_failure(scraper: {{ class_name }}Scraper):
    """Test handling of download failures."""
    with patch('requests.get') as mock_get:
        mock_get.side_effect = requests.RequestException("Connection error")
        
        with pytest.raises(requests.RequestException):
            await scraper.download_html()


@pytest.mark.asyncio
async def test_fetch_api_data_success(scraper: {{ class_name }}Scraper, mock_json_response: Dict[str, Any]):
    """Test successful API data fetch."""
    with patch('httpx.AsyncClient') as mock_client_class:
        mock_client = AsyncMock()
        mock_response = Mock()
        mock_response.json.return_value = mock_json_response
        mock_response.raise_for_status = Mock()
        mock_client.get.return_value = mock_response
        mock_client_class.return_value.__aenter__.return_value = mock_client
        
        result = await scraper.fetch_api_data("test/endpoint", params={"key": "value"})
        
        assert result == mock_json_response
        mock_client.get.assert_called_once()


@pytest.mark.asyncio
async def test_fetch_api_data_failure(scraper: {{ class_name }}Scraper):
    """Test handling of API fetch failures."""
    with patch('httpx.AsyncClient') as mock_client_class:
        mock_client = AsyncMock()
        mock_client.get.side_effect = httpx.HTTPError("API error")
        mock_client_class.return_value.__aenter__.return_value = mock_client
        
        with pytest.raises(httpx.HTTPError):
            await scraper.fetch_api_data("test/endpoint")


def test_parse_html(scraper: {{ class_name }}Scraper, mock_html_response: str):
    """Test HTML parsing."""
    # TODO: Update this test based on actual HTML structure
    locations = scraper.parse_html(mock_html_response)
    
    assert len(locations) == 1
    assert locations[0]["name"] == "Sample Food Pantry"
    assert locations[0]["address"] == "123 Main St, City, {{ state }} 12345"
    assert locations[0]["phone"] == "(555) 123-4567"
    assert locations[0]["hours"] == "Mon-Fri 9am-5pm"


def test_parse_html_empty(scraper: {{ class_name }}Scraper):
    """Test parsing empty HTML."""
    locations = scraper.parse_html("<html><body></body></html>")
    assert locations == []


def test_process_api_response(scraper: {{ class_name }}Scraper, mock_json_response: Dict[str, Any]):
    """Test API response processing."""
    locations = scraper.process_api_response(mock_json_response)
    
    assert len(locations) == 1
    assert locations[0]["name"] == "Sample Food Pantry"
    assert locations[0]["address"] == "123 Main St, City, {{ state }} 12345"


def test_process_api_response_empty(scraper: {{ class_name }}Scraper):
    """Test processing empty API response."""
    locations = scraper.process_api_response({})
    assert locations == []


@pytest.mark.asyncio
async def test_scrape_html_flow(scraper: {{ class_name }}Scraper, mock_html_response: str):
    """Test complete HTML scraping flow."""
    # Mock download_html
    scraper.download_html = AsyncMock(return_value=mock_html_response)
    
    # Track submitted jobs
    submitted_jobs = []
    
    def mock_submit(content: str) -> str:
        submitted_jobs.append(json.loads(content))
        return f"job-{len(submitted_jobs)}"
    
    scraper.submit_to_queue = Mock(side_effect=mock_submit)
    
    # Run scraper
    summary_json = await scraper.scrape()
    summary = json.loads(summary_json)
    
    # Verify summary
    assert summary["scraper_id"] == "{{ scraper_id }}"
    assert summary["food_bank"] == "{{ food_bank_name }}"
    assert summary["total_locations_found"] == 1
    assert summary["unique_locations"] == 1
    assert summary["total_jobs_created"] == 1
    assert summary["test_mode"] is True
    
    # Verify submitted jobs
    assert len(submitted_jobs) == 1
    job = submitted_jobs[0]
    assert job["name"] == "Sample Food Pantry"
    # Note: Geocoding is now done by validator service, so lat/long may be None
    assert job["source"] == "{{ scraper_id }}"
    assert job["food_bank"] == "{{ food_bank_name }}"


@pytest.mark.asyncio
async def test_scrape_without_coordinates(scraper: {{ class_name }}Scraper, mock_html_response: str):
    """Test scraping when coordinates are not available."""
    # Mock download_html
    scraper.download_html = AsyncMock(return_value=mock_html_response)
    
    # Track submitted jobs
    submitted_jobs = []
    
    def mock_submit(content: str) -> str:
        submitted_jobs.append(json.loads(content))
        return f"job-{len(submitted_jobs)}"
    
    scraper.submit_to_queue = Mock(side_effect=mock_submit)
    
    # Run scraper
    summary_json = await scraper.scrape()
    summary = json.loads(summary_json)
    
    # Verify job was submitted without coordinates (validator will handle geocoding)
    assert len(submitted_jobs) == 1
    job = submitted_jobs[0]
    # Coordinates might be None - that's ok, validator service will geocode
    assert "latitude" in job  # Key should exist even if None
    assert "longitude" in job  # Key should exist even if None


def test_scraper_initialization():
    """Test scraper initialization."""
    # Test with default ID
    scraper1 = {{ class_name }}Scraper()
    assert scraper1.scraper_id == "{{ scraper_id }}"
    assert scraper1.test_mode is False
    
    # Test with custom ID
    scraper2 = {{ class_name }}Scraper(scraper_id="custom_id")
    assert scraper2.scraper_id == "custom_id"
    
    # Test with test mode
    scraper3 = {{ class_name }}Scraper(test_mode=True)
    assert scraper3.test_mode is True
    assert scraper3.batch_size == 3  # Reduced in test mode
    assert scraper3.request_delay == 0.05  # Reduced in test mode


@pytest.mark.asyncio
async def test_scrape_api_flow(scraper: {{ class_name }}Scraper, mock_json_response: Dict[str, Any]):
    """Test complete API scraping flow."""
    # Mock API fetch
    scraper.fetch_api_data = AsyncMock(return_value=mock_json_response)
    
    # Override parse_html to use process_api_response instead
    scraper.parse_html = Mock(side_effect=lambda x: scraper.process_api_response(mock_json_response))
    
    # Track submitted jobs
    submitted_jobs = []
    
    def mock_submit(content: str) -> str:
        submitted_jobs.append(json.loads(content))
        return f"job-{len(submitted_jobs)}"
    
    scraper.submit_to_queue = Mock(side_effect=mock_submit)
    
    # Run scraper
    summary_json = await scraper.scrape()
    summary = json.loads(summary_json)
    
    # Verify summary
    assert summary["total_jobs_created"] == 1
    assert len(submitted_jobs) == 1